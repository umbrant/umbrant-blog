<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

	<head>
		<title>
			
			External sorting of large datasets : umbrant
			
		</title>

		<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
		<link rel="icon" type="image/ico" href="/favicon.ico"/>

		
		<link rel="alternate" type="application/atom+xml" href="http://feeds.feedburner.com/UmbrantBlog" title="umbrant"/>
		

		
		<link href="/media/css/style.css" rel="stylesheet" type="text/css" media="screen" />
		<link href="/media/css/pygments.css" rel="stylesheet" type="text/css" media="screen" />
		<link href='http://fonts.googleapis.com/css?family=Quattrocento|Droid+Sans|Droid+Sans+Mono' rel='stylesheet' type='text/css'/>
		
		
		

		
		<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
		<script type="text/javascript" src="/media/js/umbrant.js"></script>
		
		<script type="text/javascript">

  			var _gaq = _gaq || [];
  			_gaq.push(['_setAccount', 'UA-4601421-1']);
  			_gaq.push(['_trackPageview']);

  			(function() {
    		 var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    		 ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    		 var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  			 })();

		 </script>
		 
		 
	 </head>

	 <body>
		 <div id="wrapper">
			<div id="page">
				<div id="page-bgtop">
					<div id="page-bgbtm">
						<div id="content">

							

	


	

		<div class="post single">
			<h2 class="title"><a href="">External sorting of large datasets</a></h2>
			
			<p class="meta"><span class="date">April 16, 2011</span></p>
			
			<div class="entry">
			

			<!-- Hyde::Article::Begin -->

<!-- Hyde::Excerpt::Begin -->

<p>This is a common interview question: how do you sort data that is bigger than memory? &#8220;Big data&#8221; in the range of tera or petabytes can now almost be considered the norm (think of Google saving every search, click, and ad impression ever), so this manifests in reality as well. This is also a canonical problem in the database world, where it is referred to as an &#8220;external&nbsp;sort&#8221;.</p>
<p>Your mind should immediately turn to divide and conquer algorithms, namely merge sort. Write out intermediate merged output to disk, and read it back in lazily for the next round. I decided this would be a fun implementation and optimization exercise to do in C. There will probably be a follow-up post, since there are lots of optimizations I haven&#8217;t yet&nbsp;implemented.</p>
<!-- Hyde::Excerpt::End -->

<h3>Introduction</h3>
<p>Guido van Rossum (the creator of Python) did this a while ago for the rather smaller (and simpler) case of <a href="http://neopythonic.blogspot.com/2008/10/sorting-million-32-bit-integers-in-2mb.html">sorting a million 32-bit integers in <span class="caps">2MB</span> of <span class="caps">RAM</span></a>. I took the same approach of a merge sort that writes intermediate runs out to files on disk, buffering file I/O to improve performance. However, since I&#8217;m targeting file sizes that are actually larger than <span class="caps">RAM</span> (e.g. a couple gigabytes), I need to do more complicated&nbsp;things.</p>
<p>The <a href="http://en.wikipedia.org/wiki/Merge_sort">basic merge sort</a> you learn in <span class="caps">CS</span> 101 recurses down to the base case of runs of just 1 element, which are progressively merged together in pairs in a logarithmic fashion (arriving at the ultimate O(n*log n) time complexity). This is inefficient for large datasets, because the merging rate is too low. If you&#8217;re sorting a <span class="caps">1GB</span> file of 32-bit integers, the first round of merging would generate <code>(1GB/sizeof(int)/2) = (2^30/2^2/2) = 2^27</code> 8-byte files, which is just too many files. This also leads to the second core problem: small disk I/Os are highly inefficient, since they result in expensive disk seeks. Writing a bunch of 8-byte (or even 8-kilobyte) files effectively randomizes your access pattern, and will choke your throughput. To avoid bad seeks, reads and writes need to be done at about the size of the disk&#8217;s buffer (about <span class="caps">16MB</span> these&nbsp;days).</p>
<p>All of my code is also <a href="https://github.com/umbrant/extsort">available on github</a> if you want to follow along, this post is based more-or-less on the <a href="https://github.com/umbrant/extsort/tree/3ce53516063bff05570736c412eed032b803ea15">initial commit</a>.</p>
<h3>Basic&nbsp;Approach</h3>
<p>So our goal is to reduce the number of files written by the first merge step, and also write these files in much bigger chunks. This can be accomplished by increasing the quantum for merging, and doing n-way instead of 2-way&nbsp;merging.</p>
<p>I increased the merge quantum by sorting each page (<span class="caps">4KB</span>) of initial input with quicksort. This way, even with just 2-way merging, the first round for our <span class="caps">1GB</span> of integers only generates <code>(1GB/page_size/2) = (2^30/2^12/2)</code> = 2^18 intermediate files, which is a lot better than 2^27, but still too large (a quarter million files is a&nbsp;lot). </p>
<p>N-way merging merges more (many more) than two runs together at once, and is basically the same algorithm as 2-way merging. This finally reduces the level of fan out to manageable levels, and means that the size of the output runs is much larger, meaning that disk I/O can be more easily batched into large <span class="caps">16MB</span> chunks. With 64-way merging we finally get down to <code>(2^18/2^6) = 2^12</code>, or 4096 intermediate files, which is a pleasant&nbsp;number.</p>
<p>A further necessary improvement is to incrementally pull large runs off disk (required for later merge steps, when the runs are too large to all fit into memory). I do this at the same granularity as my other I/O operations: <span class="caps">16MB</span>. Currently, this decides the degree of fan out as well, since I pack as many <span class="caps">16MB</span> buffers into memory as I&#8217;m allowed, and n-way merge across all of them. This could be a problem if oodles and oodles of memory are allocated to the sort (since n gets large), but my computer with <span class="caps">4GB</span> of <span class="caps">RAM</span> can only hold 256 runs, which isn&#8217;t that&nbsp;many.</p>
<h3>Miscellaneous&nbsp;notes</h3>
<p>There are a few other miscellaneous notes. I ran into the per-process fd limit when doing large merges, so files have to be closed and reopened at the correct offset. I also parallelize the initial quicksorting of pages with a simple worker pool, which really helps speed up the first layer of merging. 
My quicksort also reduces recursion depth by bubblesorting for runs smaller than 5, which is okay since bubblesort is efficient on tiny sets (worst case 6 compares, 6 swaps, compare that to insertion sort). This might or might not increase performance, but it&#8217;s fun. Finally, even if 256 buffers can fit into memory, one buffer must always be reserved to be an output buffer (meaning you can do at most a 255-way merge). There&#8217;s also some <code>O(n)</code> memory overhead outside of just storing the data buffers, which you need to be aware of if your memory bound is especially&nbsp;tight.</p>
<h3>Benchmarking</h3>
<p>Enough discussion, onto the numbers! This is a situation where I feel like building an autotuner, since my envisioned final version will have a number of knobs to tweak (a future project I suppose). Right now, the two knobs I have to play with are the size of the overall buffer, and the size of I/O&nbsp;buffers. </p>
<p>I took two sets of numbers. The first set was taken on my laptop, which is a Intel Core i7-620M supporting 4 hyperthreads, <span class="caps">4GB</span> of <span class="caps">RAM</span>, and a 7200 <span class="caps">RPM</span> disk. The second set was taken on my desktop, an <span class="caps">AMD</span> Phenom <span class="caps">II</span> X4 965 Black Edition supporting 4 hardware threads, <span class="caps">4GB</span> of <span class="caps">RAM</span>, and an <span class="caps">60GB</span> <span class="caps">OCZ</span> Vertex 2 <span class="caps">SSD</span>. The <span class="caps">SSD</span> should help for the smaller I/O buffer sizes, but sequential access shouldn&#8217;t be too far&nbsp;apart.</p>
<p><img alt="Desktop mergesort" src="external_sorting/extsort_desktop.png" /></p>
<p><img alt="Laptop mergesort" src="external_sorting/extsort_laptop.png" /></p>
<p>I found these numbers pretty interesting. Each line represents a different total memory size. The graphs indicate that increasing the number of I/O buffer pages leads to better performance as expected, but the small total memory sizes end up performing generally better. Furthermore, my laptop performs better than my desktop with the&nbsp;<span class="caps">SSD</span>.</p>
<p>This can be interpreted as follows. First, linking the fan out of the merge to total memory size is a bad idea. The following table helps make this&nbsp;clear.</p>
<table border=1>
    <tr>
        <th colspan=4>Fan out of n-way merge</th>
    </tr>
    <tr>
        <td></td>
        <th colspan=3>Number of I/O buffer pages (4k)</th>
    </tr>
    <tr>
        <th>Total memory (<span class="caps">MB</span>)</th>
        <td>1024</td><td>2048</td><td>4096</td>
    </tr>
    <tr>
        <td>64</td><td>15</td><td>7</td><td>3</td>
    </tr>
    <tr>
        <td>128</td><td>31</td><td>15</td><td>7</td>
    </tr>
    <tr>
        <td>256</td><td>63</td><td>31</td><td>15</td>
    </tr>
    <tr>
        <td>384</td><td>95</td><td>47</td><td>23</td>
    </tr>
    <tr>
        <td>512</td><td>127</td><td>63</td><td>31</td>
    </tr>
</table>

<p>By looking at the laptop graph and this table together, we see that high fanout for <span class="caps">512MB</span> is killing performance, since it&#8217;s fine when fan out drops down to 31 at 4096 buffer pages. Conversely, the <span class="caps">64MB</span> case suffers the opposite problem at 4096 pages; a fan out of 3 is too low. Since the two fastest completion times were both with a fan out of 7 (<span class="caps">64MB</span> with 2048 pages, <span class="caps">128MB</span> with 4096 pages), I&#8217;m betting that it&#8217;s around here, but this requires further tuning to decide for&nbsp;sure.</p>
<p>The second finding is that the sort is currently <span class="caps">CPU</span> bound. This isn&#8217;t what I expected since there&#8217;s a lot of disk I/O, but it seems that the I/O batching techniques are effective. Otherwise, the desktop with the <span class="caps">SSD</span> should outpace the laptop. Furthermore, since merging is still single-threaded, the i7 laptop actually might have an advantage because of <a href="http://en.wikipedia.org/wiki/Intel_Turbo_Boost">Turbo Boost</a> kicking up single core performance above the Phenom <span class="caps">II</span>&nbsp;desktop.</p>
<p>Also note that for the relatively low fan outs at 64 and <span class="caps">128MB</span>, the desktop with the <span class="caps">SSD</span> has very flat performance as the size of the I/O buffer changes. This is the beauty of fast random accesses, and might be exploitable for better performance since you can save on memory usage by shrinking the I/O&nbsp;buffers.</p>
<h3>Future&nbsp;work</h3>
<p>Both of the aforementioned performance issues can be solved by parallelizing the merge step by running multiple n-way merges simultaneously. This lowers the fanout while still using all available memory, and will better balance <span class="caps">CPU</span> and I/O time. The number of threads and fan-out of the merge can be parameterized separately, adding two more tuning knobs to the existing knobs of total memory usage and size of I/O buffer (autotuner&nbsp;time?).</p>
<p>Another potential performance improvement is <a href="http://en.wikipedia.org/wiki/Multiple_buffering">double buffering</a>. This is essentially asynchronous I/O; instead of waiting synchronously for an I/O operation to complete, the <span class="caps">CPU</span> switches over to a second buffer and continues processing data. This comes at the cost of doubling memory usage (two buffers instead of one), but is probably especially beneficial for the write buffer since it&#8217;s so&nbsp;active.</p>
<p>There are a few more minor performance tweaks I can think of, but no more really fundamental ones. Let me know in the comments if there&#8217;s something I&#8217;ve&nbsp;missed.</p>
<p>A natural extension to this is parallel sorting with multiple machines, but I don&#8217;t plan on taking this little C codebase that far. Better to do it properly with Hadoop in a lot less&nbsp;code.</p>
<h3>Conclusion</h3>
<p>My best case sorts <span class="caps">1GB</span> of 32-bit integers in 127 seconds in <span class="caps">64MB</span> of memory on my laptop, and I think there&#8217;s at least a 2x improvement left with bigger memory sizes. I really enjoy this kind of performance analysis and tuning, since it requires thinking about the storage hierarchy, memory management, and parallelism. It&#8217;s been a reasonable two-day project, and I could see this being assigned as an undergrad course project. It doesn&#8217;t feel altogether too different from research either, just at a much smaller&nbsp;scale.</p>
<p>Once again, all the code is available <a href="https://github.com/umbrant/extsort">at github</a>.</p>
<!-- Hyde::Article::End -->

			
			</div>
		</div>


	
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'umbrant'; // required: replace example with your forum shortname

    // The following are highly recommended additional parameters. Remove the slashes in front to use.
    var disqus_identifier = '/blog/2011/external_sorting.html';
    var disqus_url = 'http://www.umbrant.com/blog/2011/external_sorting.html';
    //var disqus_developer = 1;

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>




						</div>
						<!-- end #content -->

						<div id="sidebar">
	<div id="logo">
		<h1><a href="/">umbrant</a></h1>
	</div>
	<div>
		<p>My name is Andrew Wang. I'm a CS PhD student at UC Berkeley working in distributed systems.</p>
	</div>
	<div id="menu">
		<ul>
			<li><a href="/">Home</a></li>
			<li><a href="/about.html">About</a></li>
			<li><a href="/research.html">Research</a></li>
			<li><a href="/contact.html">Contact</a></li>
		</ul>
	</div>
	<ul>
		<li>
		<h2>Recent Posts</h2>
		<ul>
			
				
			
				

					
					
						
					
						
						<li><a href="/blog/2012/twitter_jvm_tuning.html">JVM Performance Tuning (notes)</a></li>
						
					
						
						<li><a href="/blog/2012/year_in_review_2011_personal.html">Year in review: 2011 (personal)</a></li>
						
					
						
						<li><a href="/blog/2012/year_in_review_2011_professional.html">Year in review: 2011 (professional)</a></li>
						
					
						
						<li><a href="/blog/2012/haystack_review.html">Paper review: Facebook Haystack</a></li>
						
					
						
						<li><a href="/blog/2011/relational_cloud_and_database_scalability.html">Paper review: Relational Cloud, Database Scalability</a></li>
						
					
				
			
				
			
				
			
				
			
				
			
		</ul>
		</li>
		<li>
		<h2>Archive</h2>
		<ul>
			
			
			
			
				
				
				<li><a href="/blog/2012/2012.html">2012</a></li>
				
				
				
				
				
				
				
				<li><a href="/blog/2011/2011.html">2011</a></li>
				
				
				
				
			
			
			
			
			
			
			
			
			
			
		</ul>
		</li>
	</ul>
</div>

						<!-- end #sidebar -->

									<div id="footer">
				<p>Copyright &copy; Andrew Wang, umbrant.com</p>
				<p>Licensed under <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">CC BY-NC-SA 3.0</a></p>
				<br/>
				<p><a href="http://feeds.feedburner.com/UmbrantBlog"><img src="/media/images/feed-icon-14x14.png" alt="feed"/>&#160; Subscribe to my feed</a></p>
			</div>

						<!-- end #footer -->

					</div>
				</div>
			</div>
			<!-- end #page -->
		</div>
	 </body>
 </html>

 