<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>umbrant blog</title><link href="http://www.umbrant.com/blog/atom.xml" rel="self"/><link href="http://www.umbrant.com"/><updated>2011-07-08T20:02:52Z</updated><id>http://www.umbrant.com</id><entry><title>Concurrency review</title><author><name>Andrew Wang</name></author><link href="http://www.umbrant.com/blog/2011/concurrency.html"/><updated>2011-07-08T19:14:00Z</updated><published>2011-07-08T19:14:00Z</published><id>http://www.umbrant.com/blog/2011/concurrency.html</id><content type="html">
       

&lt;!-- Hyde::Excerpt::Begin --&gt;

&lt;p&gt;I assume that everyone has already read Andrew Birrell&amp;#8217;s &lt;a href=&quot;ftp://apotheca.hpl.hp.com/pub/dec/SRC/research-reports/SRC-035.pdf&quot;&gt;seminal paper on &amp;#8220;Programming with Threads&amp;#8221;&lt;/a&gt; or at least has a basic conception of parallel programming. This is going to deal with locking and concurrency at a higher level. At-bat today are five selected papers on&amp;nbsp;concurrency:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&quot;dquo&quot;&gt;&amp;#8220;&lt;/span&gt;Granularity of Locks and Degrees of Consistency in a Shared Data Base&amp;#8221;, by Gray et al.,&amp;nbsp;1975&lt;/li&gt;
&lt;li&gt;&lt;span class=&quot;dquo&quot;&gt;&amp;#8220;&lt;/span&gt;Experience with Processes and Monitors in Mesa&amp;#8221;, Lampson and Redell,&amp;nbsp;1980&lt;/li&gt;
&lt;li&gt;&lt;span class=&quot;dquo&quot;&gt;&amp;#8220;&lt;/span&gt;On Optimistic Methods for Concurrency Control&amp;#8221;, Kung and Robinson,&amp;nbsp;1981&lt;/li&gt;
&lt;li&gt;&lt;span class=&quot;dquo&quot;&gt;&amp;#8220;&lt;/span&gt;Threads and Input/Output in the Synthesis Kernel&amp;#8221;, Massalin and Pa,&amp;nbsp;1989&lt;/li&gt;
&lt;li&gt;&lt;span class=&quot;dquo&quot;&gt;&amp;#8220;&lt;/span&gt;Concurrency Control Performance Modeling: Alternatives and Implications&amp;#8221;, Agrawal, Carey and Livny,&amp;nbsp;1987&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Hyde::Excerpt::End --&gt;

&lt;h3&gt;Background&lt;/h3&gt;
&lt;p&gt;I know I said I expected Birrell&amp;#8217;s paper as base knowledge, but here&amp;#8217;s a &lt;span class=&quot;caps&quot;&gt;TLDR&lt;/span&gt; that might let you skip&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;The need for locking is derived from the concurrent reader/writer problem. It&amp;#8217;s safe for multiple threads to be reading the same data at the same time, but it&amp;#8217;s not safe to read or write while someone else is writing since you can get corrupted results. This requires the idea of the &lt;a href=&quot;http://en.wikipedia.org/wiki/Readers-writer_lock&quot;&gt;reader-writer lock&lt;/a&gt;, which allows any number of concurrent readers, but will make sure that any writer gets exclusive access (i.e. no other readers or writers are accessing the protected data). This is also called shared/exclusive locking, and is an especially common construct in parallel&amp;nbsp;programming.&lt;/p&gt;
&lt;h3&gt;Granularity of&amp;nbsp;Locks&lt;/h3&gt;
&lt;p&gt;The important takeaway from this Jim Gray paper is the idea of &lt;em&gt;hierarchal locking&lt;/em&gt;, where locking a database table also locks all the rows and row fields in that table. This hierarchal structure allows locking at an almost arbitrary granularity depending on the needs of the executing query, which ameliorates the issues that can happen with too-fine-grained locking (excessive lock overhead from doing lots of acquisitions and releases) or too-coarse-grained locking (poor concurrency from unnecessary lock&amp;nbsp;contention). &lt;/p&gt;
&lt;p&gt;This scheme applies to exclusive (X) locks used for writes as well as share (S) locks used for reads, but also requires the introduction of a third lock type: &lt;em&gt;intention locks&lt;/em&gt;. Intention locks are used to indicate in an ancestor node that one of its children has been locked, preventing another query from falsely locking the ancestor, and thus, the child as well. This is refined to having both a &lt;em&gt;intention share lock&lt;/em&gt; (&lt;span class=&quot;caps&quot;&gt;IS&lt;/span&gt;) and an &lt;em&gt;intention exclusive lock&lt;/em&gt; (&lt;span class=&quot;caps&quot;&gt;IX&lt;/span&gt;) to allow concurrent reads, since intention share locks are compatible. Exclusive intention locks are also compatible, since they still have to ultimately exclusively lock the child they want to modify. Queries are required to leave a breadcrumb trail of correct intention locks behind as they traverse toward what they ultimately want to access. Locks also must be released in leaf-to-root order, so the locking hierarchy remains&amp;nbsp;consistent.&lt;/p&gt;
&lt;p&gt;One more intention lock type is introduced for yet better concurrency: &lt;em&gt;share and intention exclusive locks&lt;/em&gt; (&lt;span class=&quot;caps&quot;&gt;SIX&lt;/span&gt;). This is interpreted as &amp;#8220;read-only access to a subtree, exclusively-locking some to be written&amp;#8221;. This is necessary because normally you can&amp;#8217;t have concurrent read/writes (cannot just first acquire the share lock and then an intention exclusive lock since they&amp;#8217;re incompatible), but since these rights are being granted to the same query, it can be depended upon not to read a row that it&amp;#8217;s currently writing. This read-modify-write behavior for a subtree is super common in databases, which is why &lt;span class=&quot;caps&quot;&gt;SIX&lt;/span&gt; locks are&amp;nbsp;important.&lt;/p&gt;
&lt;p&gt;Table 1 on page 5 of the paper is a concise rundown of what locks are compatible with each other. It might be a nice exercise to work through (the lock types being null, &lt;span class=&quot;caps&quot;&gt;IS&lt;/span&gt;, &lt;span class=&quot;caps&quot;&gt;IX&lt;/span&gt;, S, &lt;span class=&quot;caps&quot;&gt;SIX&lt;/span&gt;,&amp;nbsp;X).&lt;/p&gt;
&lt;p&gt;The rest of the paper seems less relevant. Gray et al. explain how this can be applied to a more dynamic graph based on locking ranges of mutable indexes, with the same strategy. I don&amp;#8217;t think this works for multiple indexes, since then the hierarchy &lt;span class=&quot;caps&quot;&gt;DAG&lt;/span&gt; is no longer a &lt;span class=&quot;caps&quot;&gt;DAG&lt;/span&gt;. They also cover the idea of &amp;#8220;degrees of consistency&amp;#8221; with tradeoffs between performance (concurrency) and recovery (consistency). I don&amp;#8217;t think real-world databases use anything except the highest degree of consistency, since the idea of unrecoverable, non-serializable transactions isn&amp;#8217;t pleasant. Anything with eventual consistency (looking at you, NoSQL) has made this&amp;nbsp;tradeoff.&lt;/p&gt;
&lt;h3&gt;Experience with Processes and Monitors in&amp;nbsp;Mesa&lt;/h3&gt;
&lt;p&gt;This paper specifies a new parallel programming language, Mesa, used to implement a new operating system, Pilot. Introducing a new language and &lt;span class=&quot;caps&quot;&gt;OS&lt;/span&gt; at the same time is pretty common, and is how we arrived at C and Unix. This is where the idea of &amp;#8220;Mesa semantics&amp;#8221; for monitors came from (compared to Hoare semantics). To put the work in proper context, apparently in 1979 one had to justify why a preemptive scheduler is required over a non-preemptive design even assuming a uniprocessor (the obvious reason being interrupt&amp;nbsp;handling).&lt;/p&gt;
&lt;p&gt;Mesa is kind of a neat language, in that any procedure can be easily forked off as a new process, and processes are first class values in the language and can be treated like any other value. This isn&amp;#8217;t to say that everything is expected to be able to run concurrently, just that the &lt;code&gt;FORK&lt;/code&gt; language construct is easy to apply. The core organizational construct in Mesa is the &amp;#8220;module&amp;#8221; or the &amp;#8220;monitor module&amp;#8221;. This is basically a way of logically organizing procedures, and specifying which of them need to acquire the monitor lock as part of&amp;nbsp;execution.&lt;/p&gt;
&lt;p&gt;This is also where &amp;#8220;Mesa semantics&amp;#8221; come in. Instead of immediately switching to a waiting process on a signal, the signaller continues running. This seems like a great win, since although it means slightly different semantics to the program, it also means fewer context&amp;nbsp;switches.&lt;/p&gt;
&lt;p&gt;The paper goes on to describe more about monitors and the&amp;nbsp;implementation.&lt;/p&gt;
&lt;h3&gt;On Optimistic Methods for Concurrency&amp;nbsp;Control&lt;/h3&gt;
&lt;p&gt;When I read this paper for 262A, it was a big eye-opener. I felt that the idea wouldn&amp;#8217;t hold up in real usage (and I think that this is true, except in the specific situations noted), but it was a refreshing approach to handling concurrency I had never thought&amp;nbsp;of.&lt;/p&gt;
&lt;p&gt;The idea behind &amp;#8220;optimistic concurrency&amp;#8221; is doing away with locking, and instead doing checking at the end before commit to see if there are any conflicts from concurrent queries, and aborting if so. In this way, even if incorrect query results are generated along the way, they are not externalized. This is speculative and will result in lots of aborted transactions (and thus wasted work) under write-heavy workloads, but as the paper says, this works wonderfully for read-heavy workloads where it&amp;#8217;s unlikely to have a&amp;nbsp;conflict.&lt;/p&gt;
&lt;p&gt;The motivation here is that locking often imposes unnecessary overhead, and can complicate things. In a locking scheme, even read-only queries need to lock rows even though they aren&amp;#8217;t modifying the data, just to indicate that the reads is happening. All this checking and verifying adds up, increasing complexity of the system, and leading to potential deadlocks which have to be resolved through a deadlock-free scheme, or deadlock detection and abort. Locking also can operate at too coarse a granularity; imagine the root node in a hierarchical locking scheme as described by Gray et al., it&amp;#8217;s basically constantly under lock contention, often times unnecessarily since queries are not necessarily operating on the same&amp;nbsp;subtrees.&lt;/p&gt;
&lt;p&gt;This is implemented by having &lt;em&gt;two-phase transactions&lt;/em&gt;, which goes &lt;em&gt;read phase&lt;/em&gt;, &lt;em&gt;validate&lt;/em&gt;, then &lt;em&gt;write phase&lt;/em&gt;. In the read phase, the transaction gathers up the names of all the objects it needs to read, defining a &lt;em&gt;read set&lt;/em&gt;. It then validates whether the transaction T_j is &lt;a href=&quot;http://en.wikipedia.org/wiki/Serializability&quot;&gt;serializable&lt;/a&gt;, checking to make sure that for all prior transactions T_i one of the following is&amp;nbsp;true:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;T_i completes its write phase before T_j starts its read phase. T_i comes entirely before T_j, so it&amp;#8217;s&amp;nbsp;fine.&lt;/li&gt;
&lt;li&gt;The write set of T_i does not intersect with the read set of T_j, and the T_i finishes writing before T_j starts writing. As long as there&amp;#8217;s no intersection, T_j&amp;#8217;s reads are safe, and as long as T_i finishes writing before T_j starts, T_j will not be overwritten by&amp;nbsp;T_i.&lt;/li&gt;
&lt;li&gt;The write set of T_i does not intersect the read or write set of T_j, and T_i finishes reading before T_j starts writing. Similar to the previous, no intersection with the read or write set makes T_j very safe, and T_i needs to finish reading before T_j starts writing to protect T_i&amp;#8217;s read&amp;nbsp;set.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This means that validation needs to check the write sets of all transactions that had finished reading but not finished writing (conditions 2 and 3). This poses an issue for long-running transactions, since the validator might be expected to keep around write-sets almost indefinitely. The proposed answer is to abort and restart the transaction, which leads to the question of how to deal with transactions that repeatedly fail validation. This is answered by write-locking the entire database and letting the &amp;#8220;starving&amp;#8221; transaction run to completion in isolation. This isn&amp;#8217;t great at all, but the assumption is that both long-running transactions and repeat-failures are&amp;nbsp;rare.&lt;/p&gt;
&lt;p&gt;The evaluation in this paper is kind of spotty. It&amp;#8217;s purely theoretical, and they chose to do their analysis on a B-tree, which is one of the better (though also common) situations because of the high fanout and low depth leading to lock contention on root nodes. They also assume a uniformly random distribution for accesses which is probably untrue (accesses are normally temporally correlated, which is why &lt;span class=&quot;caps&quot;&gt;LRU&lt;/span&gt; caching&amp;nbsp;works).&lt;/p&gt;
&lt;p&gt;All-in-all, this is the system design maxim of &amp;#8220;optimize for the common case&amp;#8221; taken to the extreme. The common case of no-conflict transactions will be faster with optimistic concurrency control, but it&amp;#8217;ll collapse under load a lot worse. Like the authors say, it&amp;#8217;s only for situations where transaction conflict is&amp;nbsp;rare.&lt;/p&gt;
&lt;h3&gt;Threads and Input/Output in the Synthesis&amp;nbsp;Kernel&lt;/h3&gt;
&lt;p&gt;This seems to be a more meta paper, where optimistic concurrency and lock-avoiding techniques were applied to an &lt;span class=&quot;caps&quot;&gt;OS&lt;/span&gt; to improve performance. It&amp;#8217;s also chock-full of system-specific jargon, which I will kindly avoid introducing. Honestly, most of what&amp;#8217;s laid out in the paper feels like a bunch of small optimizations for a specialized kernel that add up to something that performs demonstrable better than SunOS. Some of these techniques might be translatable back to Unix-y implementations, some of it is unique to the system (runtime optimization of syscalls?), and some of it is because it&amp;#8217;s a special-purpose kernel. I like how the references are to the SunOS source code, &lt;span class=&quot;caps&quot;&gt;GEB&lt;/span&gt; (yes, the Hofstadter book), 3 of the author&amp;#8217;s own papers, and then two external. Certainly a different&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;The takeaways here are unclear. The conclusion of &amp;#8220;avoid synchronization when possible&amp;#8221; seems hardly novel, and it feels too much like they implemented to optimize their microbenchmarks (no real apps were&amp;nbsp;written).&lt;/p&gt;
&lt;h3&gt;Concurrency Control Performance&amp;nbsp;Modeling&lt;/h3&gt;
&lt;p&gt;This paper does a deep comparison between three concurrency control algorithms: blocking locks, immediate restart on lock contention, and optimistic concurrency. I really love papers like this one, since they take a bunch of different algorithms that all tested well under different model assumptions, carefully dismantle said assumptions, and reveal real truths with their own meticulous performance model. It really demonstrates the authors&amp;#8217; complete understanding of the problem at&amp;nbsp;hand.&lt;/p&gt;
&lt;p&gt;There are a number of model parameters that are crucial to performance here. The &lt;em&gt;database system model&lt;/em&gt; specifies the physical hardware (CPUs and disks), associated schedulers, characteristics of the &lt;span class=&quot;caps&quot;&gt;DB&lt;/span&gt; (size and granularity), load control mechanisms, and the concurrency control algorithm itself. The &lt;em&gt;user model&lt;/em&gt; specifies the arrival process for users, and the type of transactions (batch or interactive). The &lt;em&gt;transaction model&lt;/em&gt; specifies the storage access pattern of a transaction, as well as its computational requirements (expressed in terms of&amp;nbsp;probabilities). &lt;/p&gt;
&lt;p&gt;I consider this to be about as complete as possible. They ignore I/O patterns and cache behavior, but those are just damn hard to model. Using a Poisson distribution for transaction inter-arrival rates is canonical without evidence to disprove it ( see &amp;#8220;On the Self-similar Nature of Ethernet Traffic&amp;#8221; by Leland et al. for a situation where Poisson does not hold so true). They also do not take into account processing time spent on the concurrency control algo itself, which feels like a slight copout since I think this means they ignore lock overhead and use a completely granular locking system (not hierarchical locking), which disfavors optimistic concurrency. This is implementation specific and a lot of additional work to add to the model, and considering there&amp;#8217;s some prior work showing that the costs are roughly comparable and negligible compared to access costs, I&amp;#8217;m willing to let it&amp;nbsp;go.&lt;/p&gt;
&lt;p&gt;The interesting part comes when they manipulate all the model parameters, and explain how different papers arrived at their different performance results. Basically, under the assumption of infinite resources, optimistic concurrency does splendidly as the level of multiprogramming increases, since locking strategies run into contention and transactions get blocked up. Optimistic transactions still face more conflicts and have to be restarted, but since there the pipeline is always full of running transactions (none are just blocked and using up a queue slot while doing no work), overall throughput continues to increase. Immediate-restart reaches an interesting performance plateau, due to its scheme of trying to match the rate of transaction completion with the rate of re-introducing restarted transactions. This was the model used in a number of prior&amp;nbsp;papers.&lt;/p&gt;
&lt;p&gt;Introducing a very resource limited situation turns things sharply in favor of blocking algos. Blocking performs much better until very high levels of multiprogramming, immediate-restart hits the same plateau for the same reason, and optimistic concurrency performs linearly worse beyond a very small multiprogramming level. Basically, every optimistic conflict detected at the end of a transaction just wasted all of the resources used; immediate restart does better since it will restart if it detects a conflict midway, and also delays restarts to match the completion&amp;nbsp;rate.&lt;/p&gt;
&lt;p&gt;Increasing the number of resources begins to favor optimistic concurrency again, but the price/performance isn&amp;#8217;t there since doubling the # of resources does not lead to a doubling in performance. They do a few more different situations, examining different workloads and model assumptions, which you can read yourself if you want to know&amp;nbsp;more.&lt;/p&gt;
&lt;p&gt;Basically, it&amp;#8217;s hard to make general statements about performance; things are dependent on your model. It seems that for most real-world use cases though (limited resources, high utilization), blocking is the concurrency control method of choice. It&amp;#8217;s also important to carefully control the level of multiprogramming for optimal throughput, since performance tends to peak and then decline as things&amp;nbsp;thrash.&lt;/p&gt;
&lt;p&gt;I also just find it really cool that they explained the performance results of a lot of previous papers within the scope of their own model, basically saying that no one was wrong, just incomplete in their&amp;nbsp;analysis.&lt;/p&gt;

   </content></entry><entry><title>Virtual memory review</title><author><name>Andrew Wang</name></author><link href="http://www.umbrant.com/blog/2011/virtual_memory.html"/><updated>2011-06-11T18:33:00Z</updated><published>2011-06-11T18:33:00Z</published><id>http://www.umbrant.com/blog/2011/virtual_memory.html</id><content type="html">
       

&lt;!-- Hyde::Excerpt::Begin --&gt;

&lt;p&gt;I&amp;#8217;m taking the &lt;span class=&quot;caps&quot;&gt;OS&lt;/span&gt; prelim this fall, which means I have to read ~100 papers this summer for background material. Since repetition aids retention, I&amp;#8217;m putting notes for papers I read up on my blog. The topics are wide-ranging, so I&amp;#8217;m trying to start with the fundamentals and then move on up to the whole-system&amp;nbsp;papers.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m kicking it off with &amp;#8220;Virtual Memory, Processes, and Sharing in &lt;span class=&quot;caps&quot;&gt;MULTICS&lt;/span&gt;&amp;#8221; by Daley and Dennis (1968) and &amp;#8220;The Multics Virtual Memory: Concepts and Design&amp;#8221; by Bensoussan, Clingen, and Daley (1972). Learn about the joys of segmentation and dynamic linking from classic papers from the 70s! These are slightly infamous papers for some systems students here at Berkeley, due to a certain past &lt;span class=&quot;caps&quot;&gt;OS&lt;/span&gt; prelim examiner grilling them on exactly these&amp;nbsp;details.&lt;/p&gt;
&lt;!-- Hyde::Excerpt::End --&gt;

&lt;h3&gt;Background&amp;nbsp;Review&lt;/h3&gt;
&lt;p&gt;Some people consider &lt;a href=&quot;http://en.wikipedia.org/wiki/Memory_segmentation&quot;&gt;segmentation&lt;/a&gt; to be the most natural way of structuring a program. Most programs are basically a collection of libraries (something really true in modern software engineering). In a segmented virtual memory system, each distinct library is placed in its own separate segment such that it has its own address space. They&amp;#8217;re still all mapped unto the same flat physical memory address space, but through per-segment base and offset&amp;nbsp;addresses.&lt;/p&gt;
&lt;p&gt;This isn&amp;#8217;t actually used much in modern operating systems for reasons I&amp;#8217;m not entirely aware of (I&amp;#8217;d guess simplicity and performance), but it&amp;#8217;s a pleasingly abstract and indirect way of organizing a program (a hallmark of&amp;nbsp;Multics).&lt;/p&gt;
&lt;h3&gt;Virtual Memory, Processes, and Sharing in&amp;nbsp;&lt;span class=&quot;caps&quot;&gt;MULTICS&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Multics structured its programs in terms of segments, which could be read/write/execute protected. Segmentation is great for doing memory protection (and something that only recently reemerged as the &lt;a href=&quot;http://en.wikipedia.org/wiki/NX_bit&quot;&gt;&lt;span class=&quot;caps&quot;&gt;NX&lt;/span&gt; bit&lt;/a&gt; for flat memory models), since it&amp;#8217;s easy to do a compare on any &lt;code&gt;(base+offset)&lt;/code&gt; calculation and see if it falls into a protected range. Segments can still of course be paged, and segmentation and paging are complementary: segmentation for protection, and paging for working set&amp;nbsp;management.&lt;/p&gt;
&lt;p&gt;Addressing in Multics is done in terms of a &lt;em&gt;generalized address&lt;/em&gt;: &lt;code&gt;(segment num + word num)&lt;/code&gt;. The segment number of the currently executing segment is stored in the &lt;em&gt;procedure base register&lt;/em&gt;, so most instructions just need to specify a word number. Indirect addressing (i.e. referencing an address stored at an address) is done with a pair of instructions to have enough bits: one for the segment number, one for the word&amp;nbsp;number.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;descriptor table&lt;/em&gt; is kept of all the segments in a program to map them to hardware addresses. This table maps seg nums to a physical address, and then adds the word num as the offset. This is similar to a page table: virtual to physical address translation. A pointer to the descriptor table is saved as part of the context information of the&amp;nbsp;process.&lt;/p&gt;
&lt;p&gt;Now for the complicated bits: dynamic linking. Clearly, we don&amp;#8217;t want each program to have to have its own copy of shared segments (say, libc), and we want some abstraction so we aren&amp;#8217;t hardcoding word numbers into our program. This also needs to work for segments linking to other segments which link to other segments, etc., so it gets a little hairy. We also want this to be reasonably fast, e.g. don&amp;#8217;t do multiple memory accesses for every dynamically linked call, at least after the first time. In list&amp;nbsp;form:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dynamically linked accesses are specially marked in the program&amp;nbsp;text&lt;/li&gt;
&lt;li&gt;Dynamically linked segments are present at a well-know &lt;em&gt;path name&lt;/em&gt;, e.g. in Linux &lt;code&gt;/usr/lib/ld-linux.so.2&lt;/code&gt;, that the system can search for and find (see&amp;nbsp;LD_LIBRARY_PATH).&lt;/li&gt;
&lt;li&gt;Each segments presents a &lt;em&gt;symbol table&lt;/em&gt;, which defines the call-in points for the segment (static vars, functions,&amp;nbsp;etc)&lt;/li&gt;
&lt;li&gt;Initially, all calls to an external function are to an indirect reference stored as &lt;em&gt;link data&lt;/em&gt; in a per-segment &lt;em&gt;linkage table&lt;/em&gt;. This table is initially set to trap to an &lt;span class=&quot;caps&quot;&gt;OS&lt;/span&gt; lookup&amp;nbsp;function. &lt;/li&gt;
&lt;li&gt;A &lt;em&gt;linkage pointer&lt;/em&gt; to the &lt;em&gt;linkage table&lt;/em&gt; is maintained to switch around the table as context changes to different&amp;nbsp;segments.&lt;/li&gt;
&lt;li&gt;On the first reference, the &lt;span class=&quot;caps&quot;&gt;OS&lt;/span&gt; lookup function finds the file of the external segment, examines its symbol table, and then &lt;em&gt;links&lt;/em&gt; the two segments by updating the link data in the linkage table. Future references use that indirect address to go straight to the external&amp;nbsp;segment.&lt;/li&gt;
&lt;li&gt;A further complication enters when switching the linkage pointers between linked segments. To determine the new value for the linkage pointer, the calling procedure actually calls into the new segment&amp;#8217;s linkage table, which has special instructions to fixup the linkage pointer and then call the called procedure.&lt;ul&gt;
&lt;li&gt;Thus: Caller -&amp;gt; Caller&amp;#8217;s linkage table ~&amp;gt; Callee&amp;#8217;s linkage table ~&amp;gt;&amp;nbsp;Callee&lt;/li&gt;
&lt;li&gt;This is direct -&amp;gt; indirect -&amp;gt; indirect, plus a fixup, seems&amp;nbsp;expensive&amp;#8230;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This really isn&amp;#8217;t that different from how Linux does it, the basic idea of &amp;#8220;keep a well-known table that fixes itself on the first reference&amp;#8221; is a winner. I feel like there are a lot of memory accesses required to traverse all these layers of indirection, since you are calling through multiple layers of indirect addressing, each of which is a pair of&amp;nbsp;instructions.&lt;/p&gt;
&lt;h3&gt;The Multics Virtual Memory: Concepts and&amp;nbsp;Design&lt;/h3&gt;
&lt;p&gt;It&amp;#8217;s weird to hear that back in the days of yore, files could not be easily loaded as program text, and the idea of virtual memory for protection, abstraction, and programmer benefit was a new idea. Users were just allocated a range of memory, or &lt;em&gt;core image&lt;/em&gt;, with no sharing between users; if you wanted to work on a &amp;#8220;shared file&amp;#8221;, that meant doing I/O to copy it into your range, and then another I/O to put it back into the filesystem. Each user&amp;#8217;s core image was also an unstructured jumble of instructions and data, which makes system-level sharing and memory protection basically&amp;nbsp;impossible.&lt;/p&gt;
&lt;p&gt;These two goals motivated the design of virtual memory in Multics: sharing and protection. This led to the &lt;em&gt;segmentation&lt;/em&gt;, where each segment appears as a flat, linear namespace to the user program, with read/write/execute/append access rights attached as metadata to the&amp;nbsp;segment.&lt;/p&gt;
&lt;p&gt;Segments are also paged to ease the allocation problem and to support large segments. &lt;em&gt;Descriptor segments&lt;/em&gt; (aka descriptor tables) are also paged for good reason, meaning 4 memory lookups to access a memory location, going through two page tables (one for the descriptor, one for the segment). TLBs work here, but it still sounds slow. Page tables are also a static size, not a&amp;nbsp;tree.&lt;/p&gt;
&lt;p&gt;This paper is a decent overview of Multics, probably would have made sense to read it before the dynamic linking&amp;nbsp;one.&lt;/p&gt;

   </content></entry><entry><title>Android: the Good, the Bad, and the Ugly</title><author><name>Andrew Wang</name></author><link href="http://www.umbrant.com/blog/2011/android_the_good_and_bad.html"/><updated>2011-05-15T23:54:00Z</updated><published>2011-05-15T23:54:00Z</published><id>http://www.umbrant.com/blog/2011/android_the_good_and_bad.html</id><content type="html">
       

&lt;!-- Hyde::Excerpt::Begin --&gt;

&lt;p&gt;Over the last week, I&amp;#8217;ve been doing a crash course in Android programming. &lt;a href=&quot;http://www.eecs.berkeley.edu/~rxin/&quot;&gt;Reynold&lt;/a&gt; and I have been working on our combination &lt;span class=&quot;caps&quot;&gt;CS294&lt;/span&gt;-35 Mobile Development project and &lt;span class=&quot;caps&quot;&gt;AMP&lt;/span&gt; Lab retreat demo, which is next week. Coming from a traditional web and application development background, there are some things Android does comparatively well, some comparatively poorly, and some that just irritate&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;This isn&amp;#8217;t a tutorial, but it&amp;#8217;d probably be a useful read if you&amp;#8217;re thinking of getting started with Android development. My pain, your&amp;nbsp;gain.&lt;/p&gt;
&lt;!-- Hyde::Excerpt::End --&gt;

&lt;h3&gt;The&amp;nbsp;Good&lt;/h3&gt;
&lt;p&gt;I like the relatively smooth integration of the Android &lt;span class=&quot;caps&quot;&gt;SDK&lt;/span&gt; with Eclipse. It&amp;#8217;s pretty easy getting to the &lt;a href=&quot;http://developer.android.com/guide/tutorials/hello-world.html&quot;&gt;Hello World&lt;/a&gt; stage with the Android emulator. Autocompletion works as expected. Debugging is easy, since the emulator will throw stacktraces in LogCat even when not in debug mode, and it&amp;#8217;s just as easy to do these things on actual phone hardware. It was also easy to get things running on a real phone; the Motorola Droid I was using didn&amp;#8217;t require Verizon activation or rooting or paying for a developers license. Check a few boxes in the settings menu, and you&amp;#8217;re off to the&amp;nbsp;races.&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s also a thriving community of Android developers. It&amp;#8217;s very easy to Google your problems (and believe me, that&amp;#8217;s important). StackOverflow seems very&amp;nbsp;helpful.&lt;/p&gt;
&lt;p&gt;I also appreciate having an emulator that works so effectively. I wish that the emulator&amp;#8217;s camera had a more useful test pattern, but that&amp;#8217;s forgivable. Otherwise, I had very few situations where the emulator behavior differed from actual&amp;nbsp;hardware.&lt;/p&gt;
&lt;h3&gt;The&amp;nbsp;Bad&lt;/h3&gt;
&lt;p&gt;There&amp;#8217;s a pretty large jump between Hello World and the next, less trivial tutorial in the series (&lt;a href=&quot;http://developer.android.com/guide/tutorials/notepad/index.html&quot;&gt;Notepad&lt;/a&gt;), and there&amp;#8217;s a huge jump from Notepad to making your own&amp;nbsp;app.&lt;/p&gt;
&lt;p&gt;Notepad introduces what has to be the messiest part of Android (and indeed, mobile) development: the &lt;a href=&quot;http://developer.android.com/reference/android/app/Activity.html&quot;&gt;application lifecycle&lt;/a&gt;. Take a look at the flowchart in that link. An Activity is basically a single screen of an application. Whene a new activity is switched in, the old one goes through &lt;code&gt;onPause()&lt;/code&gt; and maybe &lt;code&gt;onStop()&lt;/code&gt;. After that, it&amp;#8217;s fair game for the Android task killer, which starts discriminately killing off applications if memory is&amp;nbsp;low.&lt;/p&gt;
&lt;p&gt;This is a huge hassle from a traditional app developer standpoint, since it used to be that the &lt;span class=&quot;caps&quot;&gt;OS&lt;/span&gt; would save all your application state on a context switch, and restore it when your app is switched back in. Modify some variables, context switch out, context switch back in, and the variables are how you left them. In Android, that&amp;#8217;s no longer true. Now, you are forced to serialize all (all!) of your live state out to one of the Android &lt;a href=&quot;http://developer.android.com/guide/topics/data/data-storage.html&quot;&gt;persistent datastores&lt;/a&gt;, which most of the time means using (SQLite)[http://developer.android.com/guide/topics/data/data-storage.html#db]. If you don&amp;#8217;t do this, it means that your app works correctly most of the time (since the task killer doesn&amp;#8217;t always kick in), but occasionally, bad things will happen: settings get reset, entered form data disappears, just plain&amp;nbsp;bugs.&lt;/p&gt;
&lt;p&gt;This becomes especially terrible when you&amp;#8217;re doing any kind of network programming. This introduces a whole mess of concepts that&amp;#8217;d require another full blog post (&lt;a href=&quot;http://developer.android.com/reference/android/app/Service.html&quot;&gt;Service&lt;/a&gt;, &lt;a href=&quot;http://developer.android.com/reference/android/content/ContentProvider.html&quot;&gt;ContentProvider&lt;/a&gt;, and &lt;a href=&quot;http://developer.android.com/guide/topics/fundamentals/processes-and-threads.html&quot;&gt;background reading&lt;/a&gt;), but the basic problem is, how do you reliably make a request to a server if your request might die at any time (due to the application&amp;nbsp;lifecycle)?&lt;/p&gt;
&lt;p&gt;You end up having to watch this &lt;a href=&quot;http://www.youtube.com/watch?v=xHXn3Kg2IQE&quot;&gt;Google I/O talk on how to correctly implement &lt;span class=&quot;caps&quot;&gt;REST&lt;/span&gt; in Android&lt;/a&gt;, which features this wonderful diagram that Reynold and I&amp;nbsp;implemented:&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;ContentProvider for REST&quot; src=&quot;android_the_good_the_bad_and_the_ugly/android_rest_diagram.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Yuck. Wasn&amp;#8217;t &lt;span class=&quot;caps&quot;&gt;REST&lt;/span&gt; supposed to be the easy&amp;nbsp;way?&lt;/p&gt;
&lt;p&gt;The very naive way of doing network requests is directly in your Activity, which blocks the &lt;span class=&quot;caps&quot;&gt;UI&lt;/span&gt; thread (leading to the app freezing) and is clearly bad practice, even to a novice. The slightly-less-naive way is using a Service, in which you have to start a new thread to make the request (or else it will again block the &lt;span class=&quot;caps&quot;&gt;UI&lt;/span&gt; thread). This will mostly work, since Services sort of run in the background, but is still prone to erratic bugs because Services are still under the authority of the Android task killer. So, you end up resorting to ContentProvider, and the filling out the 6 boxes in the diagram you see&amp;nbsp;above.&lt;/p&gt;
&lt;p&gt;The same story can be found for getting phone location. The &lt;a href=&quot;http://developer.android.com/guide/topics/location/obtaining-user-location.html&quot;&gt;documentation page&lt;/a&gt; isn&amp;#8217;t bad, but it quickly becomes obvious that it&amp;#8217;s complicated to do it both correctly and well. Your app has to balance using &lt;span class=&quot;caps&quot;&gt;GPS&lt;/span&gt; vs. celltower triangulation based on accuracy and availability, cache old locations to get an initial fast fix, invalidate said cached locations if they&amp;#8217;re too old or too inaccurate, and minimizing overall usage of these radios since they&amp;#8217;re the biggest battery killers in a phone. It&amp;#8217;s a lot of manual heavy lifting to do it right, and it&amp;#8217;s easy to do it incorrectly (presenting inaccurate result) and poorly (quickly draining&amp;nbsp;battery).&lt;/p&gt;
&lt;h3&gt;The&amp;nbsp;Ugly&lt;/h3&gt;
&lt;p&gt;These are some random warts in the platform, not fundamental issues, but annoying (and&amp;nbsp;fixable).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There are a lot of concepts thrown at you in the tutorials, and Notepad doesn&amp;#8217;t go far enough. I&amp;#8217;d like to see some more tutorials, and more beginner-friendly explanations of classes like Activity, Service, Intent, and View, and some high-level advice on designing for the antagonistic application&amp;nbsp;lifecycle.&lt;/li&gt;
&lt;li&gt;The development emulator is really slow. It takes a few minutes to start up, and there&amp;#8217;s definitely lag while operating it. Comparatively, the iPhone emulator starts almost instantaneously, and feels just as snappy as a real&amp;nbsp;iPhone.&lt;/li&gt;
&lt;li&gt;No tutorial on how to programatically build a &lt;span class=&quot;caps&quot;&gt;UI&lt;/span&gt;. I get that &lt;span class=&quot;caps&quot;&gt;XML&lt;/span&gt; is the preferred way since you can do it graphically in Eclipse, but that falls short pretty&amp;nbsp;fast.&lt;/li&gt;
&lt;li&gt;The &lt;span class=&quot;caps&quot;&gt;XML&lt;/span&gt; layout is decidedly less powerful than &lt;span class=&quot;caps&quot;&gt;CSS&lt;/span&gt;+&lt;span class=&quot;caps&quot;&gt;HTML&lt;/span&gt;. No templates, no style rules, lots of repeating the same padding, margin, and textsize parameters in each file. It&amp;#8217;s a nightmare for maintainability; fortunately mobile UIs are&amp;nbsp;simple.&lt;/li&gt;
&lt;li&gt;There isn&amp;#8217;t a provided library of icons. I think this is a no brainer; I want some basic icons for things like &amp;#8220;list&amp;#8221;, &amp;#8220;settings&amp;#8221;, &amp;#8220;home&amp;#8221; that I see used in core Android, but these aren&amp;#8217;t available in the&amp;nbsp;&lt;span class=&quot;caps&quot;&gt;SDK&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;I can&amp;#8217;t figure out how to do not-fullscreen Google Maps with panning and zoom. iPhone can do it, but somehow all the Android maps I see that support pan+zoom are&amp;nbsp;fullscreen.&lt;/li&gt;
&lt;li&gt;Hardware and software keyboards have different event listeners and behaviors. Software keyboard has an unfortunate habit of staying open even when changing tabs in a&amp;nbsp;TabView.&lt;/li&gt;
&lt;li&gt;I disliked having to write something like 4 serialization/deserialization routines for every object. This was due to having to store all my state as Java objects, in SQLite, in &lt;span class=&quot;caps&quot;&gt;JSON&lt;/span&gt; to talk to the server over &lt;span class=&quot;caps&quot;&gt;REST&lt;/span&gt;, and also as visible data on screen. An &lt;span class=&quot;caps&quot;&gt;ORM&lt;/span&gt; or something would be&amp;nbsp;great.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;This experience made me realize why many Android apps suck: it&amp;#8217;s hard to do things the right way, and easy to hack it together the wrong way. I don&amp;#8217;t think Android is alone on this one, from what I hear, iPhone isn&amp;#8217;t much different in terms of application lifecycle. From the &lt;span class=&quot;caps&quot;&gt;OS&lt;/span&gt; point of view, it&amp;#8217;s great that any app can be killed at any time to save resources. I&amp;#8217;m betting this results in huge wins in battery life, performance, and code size. However, it just shifts that burden onto app developers, who aren&amp;#8217;t used to doing this kind of thing, and there aren&amp;#8217;t libraries or APIs in place to make this as easy as it should&amp;nbsp;be.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m not totally turned off of mobile app development, since I still believe that mobile is essentially the future of computing, but I really think it could be a lot better. Personally, &lt;span class=&quot;caps&quot;&gt;HP&lt;/span&gt;&amp;#8217;s webOS appeals to me since &lt;span class=&quot;caps&quot;&gt;HTML&lt;/span&gt;+&lt;span class=&quot;caps&quot;&gt;CSS&lt;/span&gt;+&lt;span class=&quot;caps&quot;&gt;JS&lt;/span&gt; is a &lt;em&gt;much&lt;/em&gt; more natural way of writing applications (and that&amp;#8217;s not just my bias as a web developer), and more pure Linux-based OSs like MeeGo are certainly easier to program (but then you lose the noted benefits of the &amp;#8220;kill anything at anytime&amp;#8221; model). I&amp;#8217;m still willing to bet on Android, but it still needs a lot of work before it&amp;#8217;s a first-class application development&amp;nbsp;environment.&lt;/p&gt;

   </content></entry><entry><title>External sorting of large datasets</title><author><name>Andrew Wang</name></author><link href="http://www.umbrant.com/blog/2011/external_sorting.html"/><updated>2011-04-16T17:24:00Z</updated><published>2011-04-16T17:24:00Z</published><id>http://www.umbrant.com/blog/2011/external_sorting.html</id><content type="html">
       

&lt;!-- Hyde::Excerpt::Begin --&gt;

&lt;p&gt;This is a common interview question: how do you sort data that is bigger than memory? &amp;#8220;Big data&amp;#8221; in the range of tera or petabytes can now almost be considered the norm (think of Google saving every search, click, and ad impression ever), so this manifests in reality as well. This is also a canonical problem in the database world, where it is referred to as an &amp;#8220;external&amp;nbsp;sort&amp;#8221;.&lt;/p&gt;
&lt;p&gt;Your mind should immediately turn to divide and conquer algorithms, namely merge sort. Write out intermediate merged output to disk, and read it back in lazily for the next round. I decided this would be a fun implementation and optimization exercise to do in C. There will probably be a follow-up post, since there are lots of optimizations I haven&amp;#8217;t yet&amp;nbsp;implemented.&lt;/p&gt;
&lt;!-- Hyde::Excerpt::End --&gt;

&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Guido van Rossum (the creator of Python) did this a while ago for the rather smaller (and simpler) case of &lt;a href=&quot;http://neopythonic.blogspot.com/2008/10/sorting-million-32-bit-integers-in-2mb.html&quot;&gt;sorting a million 32-bit integers in &lt;span class=&quot;caps&quot;&gt;2MB&lt;/span&gt; of &lt;span class=&quot;caps&quot;&gt;RAM&lt;/span&gt;&lt;/a&gt;. I took the same approach of a merge sort that writes intermediate runs out to files on disk, buffering file I/O to improve performance. However, since I&amp;#8217;m targeting file sizes that are actually larger than &lt;span class=&quot;caps&quot;&gt;RAM&lt;/span&gt; (e.g. a couple gigabytes), I need to do more complicated&amp;nbsp;things.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Merge_sort&quot;&gt;basic merge sort&lt;/a&gt; you learn in &lt;span class=&quot;caps&quot;&gt;CS&lt;/span&gt; 101 recurses down to the base case of runs of just 1 element, which are progressively merged together in pairs in a logarithmic fashion (arriving at the ultimate O(n*log n) time complexity). This is inefficient for large datasets, because the merging rate is too low. If you&amp;#8217;re sorting a &lt;span class=&quot;caps&quot;&gt;1GB&lt;/span&gt; file of 32-bit integers, the first round of merging would generate &lt;code&gt;(1GB/sizeof(int)/2) = (2^30/2^2/2) = 2^27&lt;/code&gt; 8-byte files, which is just too many files. This also leads to the second core problem: small disk I/Os are highly inefficient, since they result in expensive disk seeks. Writing a bunch of 8-byte (or even 8-kilobyte) files effectively randomizes your access pattern, and will choke your throughput. To avoid bad seeks, reads and writes need to be done at about the size of the disk&amp;#8217;s buffer (about &lt;span class=&quot;caps&quot;&gt;16MB&lt;/span&gt; these&amp;nbsp;days).&lt;/p&gt;
&lt;p&gt;All of my code is also &lt;a href=&quot;https://github.com/umbrant/extsort&quot;&gt;available on github&lt;/a&gt; if you want to follow along, this post is based more-or-less on the &lt;a href=&quot;https://github.com/umbrant/extsort/tree/3ce53516063bff05570736c412eed032b803ea15&quot;&gt;initial commit&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Basic&amp;nbsp;Approach&lt;/h3&gt;
&lt;p&gt;So our goal is to reduce the number of files written by the first merge step, and also write these files in much bigger chunks. This can be accomplished by increasing the quantum for merging, and doing n-way instead of 2-way&amp;nbsp;merging.&lt;/p&gt;
&lt;p&gt;I increased the merge quantum by sorting each page (&lt;span class=&quot;caps&quot;&gt;4KB&lt;/span&gt;) of initial input with quicksort. This way, even with just 2-way merging, the first round for our &lt;span class=&quot;caps&quot;&gt;1GB&lt;/span&gt; of integers only generates &lt;code&gt;(1GB/page_size/2) = (2^30/2^12/2)&lt;/code&gt; = 2^18 intermediate files, which is a lot better than 2^27, but still too large (a quarter million files is a&amp;nbsp;lot). &lt;/p&gt;
&lt;p&gt;N-way merging merges more (many more) than two runs together at once, and is basically the same algorithm as 2-way merging. This finally reduces the level of fan out to manageable levels, and means that the size of the output runs is much larger, meaning that disk I/O can be more easily batched into large &lt;span class=&quot;caps&quot;&gt;16MB&lt;/span&gt; chunks. With 64-way merging we finally get down to &lt;code&gt;(2^18/2^6) = 2^12&lt;/code&gt;, or 4096 intermediate files, which is a pleasant&amp;nbsp;number.&lt;/p&gt;
&lt;p&gt;A further necessary improvement is to incrementally pull large runs off disk (required for later merge steps, when the runs are too large to all fit into memory). I do this at the same granularity as my other I/O operations: &lt;span class=&quot;caps&quot;&gt;16MB&lt;/span&gt;. Currently, this decides the degree of fan out as well, since I pack as many &lt;span class=&quot;caps&quot;&gt;16MB&lt;/span&gt; buffers into memory as I&amp;#8217;m allowed, and n-way merge across all of them. This could be a problem if oodles and oodles of memory are allocated to the sort (since n gets large), but my computer with &lt;span class=&quot;caps&quot;&gt;4GB&lt;/span&gt; of &lt;span class=&quot;caps&quot;&gt;RAM&lt;/span&gt; can only hold 256 runs, which isn&amp;#8217;t that&amp;nbsp;many.&lt;/p&gt;
&lt;h3&gt;Miscellaneous&amp;nbsp;notes&lt;/h3&gt;
&lt;p&gt;There are a few other miscellaneous notes. I ran into the per-process fd limit when doing large merges, so files have to be closed and reopened at the correct offset. I also parallelize the initial quicksorting of pages with a simple worker pool, which really helps speed up the first layer of merging. 
My quicksort also reduces recursion depth by bubblesorting for runs smaller than 5, which is okay since bubblesort is efficient on tiny sets (worst case 6 compares, 6 swaps, compare that to insertion sort). This might or might not increase performance, but it&amp;#8217;s fun. Finally, even if 256 buffers can fit into memory, one buffer must always be reserved to be an output buffer (meaning you can do at most a 255-way merge). There&amp;#8217;s also some &lt;code&gt;O(n)&lt;/code&gt; memory overhead outside of just storing the data buffers, which you need to be aware of if your memory bound is especially&amp;nbsp;tight.&lt;/p&gt;
&lt;h3&gt;Benchmarking&lt;/h3&gt;
&lt;p&gt;Enough discussion, onto the numbers! This is a situation where I feel like building an autotuner, since my envisioned final version will have a number of knobs to tweak (a future project I suppose). Right now, the two knobs I have to play with are the size of the overall buffer, and the size of I/O&amp;nbsp;buffers. &lt;/p&gt;
&lt;p&gt;I took two sets of numbers. The first set was taken on my laptop, which is a Intel Core i7-620M supporting 4 hyperthreads, &lt;span class=&quot;caps&quot;&gt;4GB&lt;/span&gt; of &lt;span class=&quot;caps&quot;&gt;RAM&lt;/span&gt;, and a 7200 &lt;span class=&quot;caps&quot;&gt;RPM&lt;/span&gt; disk. The second set was taken on my desktop, an &lt;span class=&quot;caps&quot;&gt;AMD&lt;/span&gt; Phenom &lt;span class=&quot;caps&quot;&gt;II&lt;/span&gt; X4 965 Black Edition supporting 4 hardware threads, &lt;span class=&quot;caps&quot;&gt;4GB&lt;/span&gt; of &lt;span class=&quot;caps&quot;&gt;RAM&lt;/span&gt;, and an &lt;span class=&quot;caps&quot;&gt;60GB&lt;/span&gt; &lt;span class=&quot;caps&quot;&gt;OCZ&lt;/span&gt; Vertex 2 &lt;span class=&quot;caps&quot;&gt;SSD&lt;/span&gt;. The &lt;span class=&quot;caps&quot;&gt;SSD&lt;/span&gt; should help for the smaller I/O buffer sizes, but sequential access shouldn&amp;#8217;t be too far&amp;nbsp;apart.&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;Desktop mergesort&quot; src=&quot;external_sorting/extsort_desktop.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;Laptop mergesort&quot; src=&quot;external_sorting/extsort_laptop.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;I found these numbers pretty interesting. Each line represents a different total memory size. The graphs indicate that increasing the number of I/O buffer pages leads to better performance as expected, but the small total memory sizes end up performing generally better. Furthermore, my laptop performs better than my desktop with the&amp;nbsp;&lt;span class=&quot;caps&quot;&gt;SSD&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This can be interpreted as follows. First, linking the fan out of the merge to total memory size is a bad idea. The following table helps make this&amp;nbsp;clear.&lt;/p&gt;
&lt;table border=1&gt;
    &lt;tr&gt;
        &lt;th colspan=4&gt;Fan out of n-way merge&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;th colspan=3&gt;Number of I/O buffer pages (4k)&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Total memory (&lt;span class=&quot;caps&quot;&gt;MB&lt;/span&gt;)&lt;/th&gt;
        &lt;td&gt;1024&lt;/td&gt;&lt;td&gt;2048&lt;/td&gt;&lt;td&gt;4096&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;64&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;128&lt;/td&gt;&lt;td&gt;31&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;256&lt;/td&gt;&lt;td&gt;63&lt;/td&gt;&lt;td&gt;31&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;384&lt;/td&gt;&lt;td&gt;95&lt;/td&gt;&lt;td&gt;47&lt;/td&gt;&lt;td&gt;23&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;512&lt;/td&gt;&lt;td&gt;127&lt;/td&gt;&lt;td&gt;63&lt;/td&gt;&lt;td&gt;31&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;By looking at the laptop graph and this table together, we see that high fanout for &lt;span class=&quot;caps&quot;&gt;512MB&lt;/span&gt; is killing performance, since it&amp;#8217;s fine when fan out drops down to 31 at 4096 buffer pages. Conversely, the &lt;span class=&quot;caps&quot;&gt;64MB&lt;/span&gt; case suffers the opposite problem at 4096 pages; a fan out of 3 is too low. Since the two fastest completion times were both with a fan out of 7 (&lt;span class=&quot;caps&quot;&gt;64MB&lt;/span&gt; with 2048 pages, &lt;span class=&quot;caps&quot;&gt;128MB&lt;/span&gt; with 4096 pages), I&amp;#8217;m betting that it&amp;#8217;s around here, but this requires further tuning to decide for&amp;nbsp;sure.&lt;/p&gt;
&lt;p&gt;The second finding is that the sort is currently &lt;span class=&quot;caps&quot;&gt;CPU&lt;/span&gt; bound. This isn&amp;#8217;t what I expected since there&amp;#8217;s a lot of disk I/O, but it seems that the I/O batching techniques are effective. Otherwise, the desktop with the &lt;span class=&quot;caps&quot;&gt;SSD&lt;/span&gt; should outpace the laptop. Furthermore, since merging is still single-threaded, the i7 laptop actually might have an advantage because of &lt;a href=&quot;http://en.wikipedia.org/wiki/Intel_Turbo_Boost&quot;&gt;Turbo Boost&lt;/a&gt; kicking up single core performance above the Phenom &lt;span class=&quot;caps&quot;&gt;II&lt;/span&gt;&amp;nbsp;desktop.&lt;/p&gt;
&lt;p&gt;Also note that for the relatively low fan outs at 64 and &lt;span class=&quot;caps&quot;&gt;128MB&lt;/span&gt;, the desktop with the &lt;span class=&quot;caps&quot;&gt;SSD&lt;/span&gt; has very flat performance as the size of the I/O buffer changes. This is the beauty of fast random accesses, and might be exploitable for better performance since you can save on memory usage by shrinking the I/O&amp;nbsp;buffers.&lt;/p&gt;
&lt;h3&gt;Future&amp;nbsp;work&lt;/h3&gt;
&lt;p&gt;Both of the aforementioned performance issues can be solved by parallelizing the merge step by running multiple n-way merges simultaneously. This lowers the fanout while still using all available memory, and will better balance &lt;span class=&quot;caps&quot;&gt;CPU&lt;/span&gt; and I/O time. The number of threads and fan-out of the merge can be parameterized separately, adding two more tuning knobs to the existing knobs of total memory usage and size of I/O buffer (autotuner&amp;nbsp;time?).&lt;/p&gt;
&lt;p&gt;Another potential performance improvement is &lt;a href=&quot;http://en.wikipedia.org/wiki/Multiple_buffering&quot;&gt;double buffering&lt;/a&gt;. This is essentially asynchronous I/O; instead of waiting synchronously for an I/O operation to complete, the &lt;span class=&quot;caps&quot;&gt;CPU&lt;/span&gt; switches over to a second buffer and continues processing data. This comes at the cost of doubling memory usage (two buffers instead of one), but is probably especially beneficial for the write buffer since it&amp;#8217;s so&amp;nbsp;active.&lt;/p&gt;
&lt;p&gt;There are a few more minor performance tweaks I can think of, but no more really fundamental ones. Let me know in the comments if there&amp;#8217;s something I&amp;#8217;ve&amp;nbsp;missed.&lt;/p&gt;
&lt;p&gt;A natural extension to this is parallel sorting with multiple machines, but I don&amp;#8217;t plan on taking this little C codebase that far. Better to do it properly with Hadoop in a lot less&amp;nbsp;code.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;My best case sorts &lt;span class=&quot;caps&quot;&gt;1GB&lt;/span&gt; of 32-bit integers in 127 seconds in &lt;span class=&quot;caps&quot;&gt;64MB&lt;/span&gt; of memory on my laptop, and I think there&amp;#8217;s at least a 2x improvement left with bigger memory sizes. I really enjoy this kind of performance analysis and tuning, since it requires thinking about the storage hierarchy, memory management, and parallelism. It&amp;#8217;s been a reasonable two-day project, and I could see this being assigned as an undergrad course project. It doesn&amp;#8217;t feel altogether too different from research either, just at a much smaller&amp;nbsp;scale.&lt;/p&gt;
&lt;p&gt;Once again, all the code is available &lt;a href=&quot;https://github.com/umbrant/extsort&quot;&gt;at github&lt;/a&gt;.&lt;/p&gt;

   </content></entry><entry><title>Album first impressions pt. 1</title><author><name>Andrew Wang</name></author><link href="http://www.umbrant.com/blog/2011/album_first_impressions_pt_1.html"/><updated>2011-04-08T00:00:00Z</updated><published>2011-04-08T00:00:00Z</published><id>http://www.umbrant.com/blog/2011/album_first_impressions_pt_1.html</id><content type="html">
       

&lt;!-- Hyde::Excerpt::Begin --&gt;

&lt;p&gt;I&amp;#8217;ve gotten some large influxes of music recently, posting my first impressions of eight albums I&amp;#8217;ve given a listen or two. It&amp;#8217;s a pretty eclectic mix, new and old stuff. Reviews are unordered, and only qualitative ratings. Unexpectedly, Kanye&amp;#8217;s newest work is my favorite album of 2010. More to&amp;nbsp;come.&lt;/p&gt;
&lt;!-- Hyde::Excerpt::End --&gt;

&lt;p&gt;&lt;strong&gt;James Brown - Love Power Peace (Live at the Olympia, Paris, 1971)&lt;/strong&gt;: I have a soft spot for live albums, and this has to be among the best. I don&amp;#8217;t have much exposure to funk (the closest thing being jazz fusion), but it&amp;#8217;s easy to fall in love with the layered big-band instrumentation, high energy, and evocative call-and-response&amp;nbsp;segments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span class=&quot;caps&quot;&gt;LCD&lt;/span&gt; Soundsystem - &lt;span class=&quot;caps&quot;&gt;LCD&lt;/span&gt; Soundsystem&lt;/strong&gt; and &lt;strong&gt;&lt;span class=&quot;caps&quot;&gt;LCD&lt;/span&gt; Soundsystem - Sound of Silver&lt;/strong&gt;: I liked their most recent album &lt;strong&gt;This Is Happening&lt;/strong&gt; quite a bit, so I checked out the rest of their discography. &lt;span class=&quot;caps&quot;&gt;LCD&lt;/span&gt; Soundsystem has a pretty unique sound, rough and unvarnished singing/spoken word over some of the dirtiest bass lines and drops I&amp;#8217;ve ever heard. It&amp;#8217;s easy to see why their work is such an appealing target for remixers and DJs. I&amp;#8217;d argue that James Murphy has taken the art of repetition to perfection, surpassing even French house demigods Daft Punk. I like these two albums less than This Is Happening, but they&amp;#8217;re still going on my coding/work playlist since they&amp;#8217;re quite listenable for long periods of&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Radiohead - King of Limbs&lt;/strong&gt;: Disappointing. I had to come around to &lt;strong&gt;In Rainbows&lt;/strong&gt;, which is now my favorite Radiohead album, but I don&amp;#8217;t think I&amp;#8217;m going to acquire the taste of King of Limbs any time soon. It feels heavily influenced by dubstep, a genre of electronic music I&amp;#8217;m not particularly infatuated with. I&amp;#8217;m willing to give King of Limbs a few more listens because of brand loyalty, but it probably won&amp;#8217;t make my list of top 5 favorite Radiohead&amp;nbsp;albums.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Regina Spektor - Begin to Hope&lt;/strong&gt;: She reminds me of Feist, but with better clarity and range. I&amp;#8217;m slowly adding female vocal music to my collection (see also: Cat Power), and this is a nice find. Where Feist has this airy, carefree feeling that permeates her music, Spektor is more raw, emotional, and pure. She also has some adorable speech impediment that makes &lt;a href=&quot;http://www.youtube.com/watch?v=5zA4oG4FJFY&quot;&gt;&amp;#8220;better&amp;#8221; sound like &amp;#8220;betto&amp;#8221;&lt;/a&gt;.&amp;nbsp;Recommended.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Little Boots - Hands&lt;/strong&gt;: I think she has mild internet fame for her videos &lt;a href=&quot;http://www.youtube.com/watch?v=-CWBgm_-Ggs&quot;&gt;playing&lt;/a&gt; a &lt;a href=&quot;http://www.youtube.com/watch?v=N6tLRCDqJ2c&quot;&gt;Tenori-on&lt;/a&gt;, and now she has an album. It&amp;#8217;s pop, which is not normally my thing, so it&amp;#8217;s a bit hard for me to judge. It&amp;#8217;s a little formulaic (expected), and reminds me of Lady Gaga, with a hip hop or alt rock feel. The autotune still grates on my ears, and is a waste of her talent. Probably won&amp;#8217;t go on my regular listening rotation, but recommended for the&amp;nbsp;genre.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Robyn - Body Talk&lt;/strong&gt;: Robyn is a Swedish pop/dance artist who turned down the recording contract that eventually went to Britney Spears. Happily, Robyn also makes much better music. I&amp;#8217;ve been watching her since happening across &lt;strong&gt;Body Talk Pt &lt;span class=&quot;caps&quot;&gt;II&lt;/span&gt;&lt;/strong&gt;; 2010 saw the release of &lt;strong&gt;Body Talk Pt I&lt;/strong&gt; and &lt;strong&gt;Body Talk Pt &lt;span class=&quot;caps&quot;&gt;II&lt;/span&gt;&lt;/strong&gt; as well as this most recent album, which pulls the hits from the first two Body Talk albums and adds a few new songs, forming what is effectively a &amp;#8220;best of&amp;#8221; compilation. Releasing three albums of new material in a year is impressive; even more impressive is the quality of each song on Body Talk. I could see any song off this album being a single. Recommended even if you don&amp;#8217;t like pop. Listen to &lt;a href=&quot;http://www.youtube.com/watch?v=fA3j3VTAsTk&quot;&gt;Fembot&lt;/a&gt; and &lt;a href=&quot;http://www.youtube.com/watch?v=ketX6HITIDU&quot;&gt;Indestructible&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kanye West - My Beautiful Dark Twisted Fantasy&lt;/strong&gt;: There&amp;#8217;s a reason this album made numerous &amp;#8220;best of 2010&amp;#8221; lists. &lt;em&gt;It&amp;#8217;s the best fucking album of 2010&lt;/em&gt;. I can hardly believe I&amp;#8217;m saying this, but I actually like it more than Arcade Fire&amp;#8217;s 2010 entry, The Suburbs. I heard &lt;span class=&quot;caps&quot;&gt;MBDTF&lt;/span&gt;&amp;#8217;s &lt;a href=&quot;http://www.youtube.com/watch?v=S-qKboHKPEA&quot;&gt;opener&lt;/a&gt;, and was already overwhelmed. I could go through and recommend each track on the album for a different reason, but I&amp;#8217;ll promote in particular &lt;a href=&quot;http://www.youtube.com/watch?v=Bm5iA4Zupek&quot;&gt;Runaway&lt;/a&gt; and &lt;a href=&quot;http://www.youtube.com/watch?v=2VOVStL0NW0&quot;&gt;Blame Game&lt;/a&gt;. Kanye was always one of the best hip-hop producers in the business, and now he&amp;#8217;s got the rapping chops to match. Sick beats abound. I love the super smooth production, every note is polished to a glossy sheen. I&amp;#8217;m impressed with the variety in styles. To conclude: I don&amp;#8217;t particularly like hip hop, I don&amp;#8217;t like Kanye&amp;#8217;s earlier work, I don&amp;#8217;t like Kanye the person, but &lt;strong&gt;My Beautiful Dark Twisted Fantasy&lt;/strong&gt; is undeniably brilliant. It&amp;#8217;s a hip hop album for the&amp;nbsp;ages.&lt;/p&gt;

   </content></entry><entry><title>Static website hosting on Amazon S3</title><author><name>Andrew Wang</name></author><link href="http://www.umbrant.com/blog/2011/static_hosting_on_s3.html"/><updated>2011-04-01T02:49:00Z</updated><published>2011-04-01T02:49:00Z</published><id>http://www.umbrant.com/blog/2011/static_hosting_on_s3.html</id><content type="html">
       

&lt;!-- Hyde::Excerpt::Begin --&gt;

&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Werner_Vogels&quot;&gt;Werner Vogels&lt;/a&gt;, Amazon &lt;span class=&quot;caps&quot;&gt;CTO&lt;/span&gt;, posted on his &lt;a href=&quot;http://www.allthingsdistributed.com/&quot;&gt;blog&lt;/a&gt; about a month ago on &amp;#8220;&lt;a href=&quot;http://www.allthingsdistributed.com/2011/02/website_amazon_s3.html&quot;&gt;New &lt;span class=&quot;caps&quot;&gt;AWS&lt;/span&gt; feature: Run your website from Amazon S3&lt;/a&gt;&amp;#8220;. S3 now offers the ability to host static &lt;span class=&quot;caps&quot;&gt;HTML&lt;/span&gt; pages directly from an S3 bucket, which is a great alternative for small blogs and sites (provided, of course, that you don&amp;#8217;t actually need any dynamic content). This has the potential to greatly reduce your hosting costs. A small Dreamhost/Slicehost/Linode costs around $20 a month, and I used to run this site out of an extreme budget &lt;span class=&quot;caps&quot;&gt;VPS&lt;/span&gt; (&lt;a href=&quot;http://virpus.com/&quot;&gt;Virpus&lt;/a&gt;) which was only $5 a month, but I expect to be paying only a few cents per month for S3 (current pricing is just &lt;a href=&quot;http://aws.amazon.com/s3/#pricing&quot;&gt;15&amp;cent; per &lt;span class=&quot;caps&quot;&gt;GB&lt;/span&gt;-month&lt;/a&gt;). Of course, you also gain best-of-class durability, fault-tolerance, and scalability from hosting out of S3, meaning that your little site should easily survive a&amp;nbsp;slashdotting.&lt;/p&gt;
&lt;!-- Hyde::Excerpt::End --&gt;

&lt;p&gt;The difficulty here is that most of the popular blogging engines require a backing database, and do their content generation dynamically server side. That doesn&amp;#8217;t fly with S3; since it is, after all, just a Simple Storage Service, content has to be static and pregenerated. I chose to use &lt;a href=&quot;http://ringce.com/hyde&quot;&gt;Hyde&lt;/a&gt;, a Python content generator that turns templates (based on the &lt;a href=&quot;http://www.djangoproject.com/&quot;&gt;Django&lt;/a&gt; templating engine) into &lt;span class=&quot;caps&quot;&gt;HTML&lt;/span&gt;. Hyde page templates are dynamic, written in &lt;a href=&quot;http://docs.djangoproject.com/en/dev/topics/templates/&quot;&gt;Django&amp;#8217;s templating language&lt;/a&gt; which supports variables, control flow, and hierarchal inheritance. Hyde will parse these templates, fill in the dynamic content, and finally generate static &lt;span class=&quot;caps&quot;&gt;HTML&lt;/span&gt; pages suitable for uploading to S3. Ruby folks can check out &lt;a href=&quot;http://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; as an&amp;nbsp;alternative.&lt;/p&gt;
&lt;h3&gt;Caveats&lt;/h3&gt;
&lt;p&gt;To be clear, purely static content won&amp;#8217;t suffice for many sites out there (like anything with user-generated content). Even a simple blog like is only feasible because there are web services that fill in the gaps in functionality. &lt;a href=&quot;http://disqus.com/&quot;&gt;Disqus&lt;/a&gt; seems to have cornered the market for comments as a service; you just include a little bit of Javascript and it&amp;#8217;s good to go. It&amp;#8217;s similarly easy to include a &lt;a href=&quot;http://tweet.seaofclouds.com/&quot;&gt;Twitter widget showing your recent tweets&lt;/a&gt; with another little blob of Javascript, and &lt;a href=&quot;http://www.feedburner.com&quot;&gt;Feedburner&lt;/a&gt; and &lt;a href=&quot;http://www.google.com/analytics/&quot;&gt;Google Analytics&lt;/a&gt; are defacto analytics tools. There&amp;#8217;s barely a need these days to scrape, store, and serve content yourself these days, further obviating the need for a real&amp;nbsp;server.&lt;/p&gt;
&lt;p&gt;This is also clearly a more coding heavy approach to blogging and site generation than most people need. With free blog services like &lt;a href=&quot;http://wordpress.com&quot;&gt;Wordpress.com&lt;/a&gt;, &lt;a href=&quot;http://www.blogger.com&quot;&gt;Blogger&lt;/a&gt;, &lt;a href=&quot;http://www.tumblr.com&quot;&gt;Tumblr&lt;/a&gt;, and &lt;a href=&quot;http://www.posterous.com&quot;&gt;Posterous&lt;/a&gt;, blogging has never been easier or more available. &lt;a href=&quot;http://sites.google.com&quot;&gt;Google Sites&lt;/a&gt; is also a great way of throwing up a quick website. I went with S3 and Hyde because I wanted more customization in the look and feel of the site, I like the Django templating system, and I wanted to play with S3 (especially since Amazon offers &lt;a href=&quot;http://aws.amazon.com/free/&quot;&gt;1 year of free &lt;span class=&quot;caps&quot;&gt;AWS&lt;/span&gt; credit&lt;/a&gt;). I also feel a bit safer about my data, since it&amp;#8217;s backed by &lt;a href=&quot;http://aws.amazon.com/s3/faqs/#How_is_Amazon_S3_designed_to_achieve_99.999999999%_durability&quot;&gt;Amazon&amp;#8217;s eleven 9&amp;#8217;s of durability&lt;/a&gt; on S3, it&amp;#8217;s on my local machine, and &lt;a href=&quot;https://github.com/umbrant/umbrant-blog&quot;&gt;under version control at github&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Hyde&lt;/h3&gt;
&lt;p&gt;Hyde is pretty straightforward for anyone with experience writing Django templates, since it&amp;#8217;s basically the Django template engine plus some extra magic content and context tags. The &lt;a href=&quot;https://github.com/lakshmivyas/hyde/blob/master/README.markdown&quot;&gt;Hyde &lt;span class=&quot;caps&quot;&gt;README&lt;/span&gt;&lt;/a&gt; and &lt;a href=&quot;https://github.com/lakshmivyas/hyde/wiki&quot;&gt;github wiki&lt;/a&gt; are somewhat helpful in laying this out. Essentially, Hyde lets you assign per-page metadata that can be accessed by other pages as they walk the directory structure of your content; your &lt;span class=&quot;caps&quot;&gt;URL&lt;/span&gt; structure mirrors your folder structure. By default, this metadata includes a &lt;code&gt;created&lt;/code&gt; field that fuels the magic &lt;code&gt;recents&lt;/code&gt; template tag which gets the most recent content from a directory (like your blog). There are a few more Hyde specific features which you can read about on &lt;a href=&quot;https://github.com/lakshmivyas/hyde/wiki/Templating-Guide&quot;&gt;the wiki page on templating&lt;/a&gt;, and the &lt;a href=&quot;http://docs.djangoproject.com/en/dev/ref/templates/builtins/&quot;&gt;Django templating reference&lt;/a&gt; is also&amp;nbsp;useful.&lt;/p&gt;
&lt;p&gt;I still found myself a little stuck, and what was most useful was reading the source for the skeleton site that Hyde generates for you initially, and the &lt;a href=&quot;https://github.com/sjl/stevelosh/&quot;&gt;code that Steve Losh&lt;/a&gt; uses to generate his own blog. To help you out, I&amp;#8217;ve &lt;a href=&quot;https://github.com/umbrant/umbrant-blog&quot;&gt;published the code&lt;/a&gt; for this site on github too. It might be useful to read &lt;a href=&quot;http://stevelosh.com/blog/2010/01/moving-from-django-to-hyde/&quot;&gt;Steve&amp;#8217;s write up on moving from Django to Hyde&lt;/a&gt; as&amp;nbsp;well.&lt;/p&gt;
&lt;p&gt;A few nice features of Hyde I like are the ability to automatically compress Javascript and &lt;span class=&quot;caps&quot;&gt;CSS&lt;/span&gt; with jsmin and cssmin, and support for writing posts in &lt;a href=&quot;http://daringfireball.net/projects/markdown/&quot;&gt;Markdown&lt;/a&gt;, which is a lot easier and more portable than &lt;span class=&quot;caps&quot;&gt;HTML&lt;/span&gt;. There&amp;#8217;s also support for writing &amp;#8220;higher level &lt;span class=&quot;caps&quot;&gt;CSS&lt;/span&gt;&amp;#8221; (CleverCSS, &lt;span class=&quot;caps&quot;&gt;HSS&lt;/span&gt;, LessCSS), but I never understood the point of these and didn&amp;#8217;t use&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;The features I had to add to the skeleton code are a draft status for posts, and the &amp;#8220;Recent Posts&amp;#8221; and &amp;#8220;Archive&amp;#8221; sections on the sidebar. Drafts were done by adding a metadata &lt;code&gt;draft: True&lt;/code&gt; tag to draft posts, and modifying all my &amp;#8220;listing&amp;#8221; pages to exclude these posts (like the home page, archive, recent posts, atom feed). The &amp;#8220;Recent Posts&amp;#8221; and &amp;#8220;Archive&amp;#8221; sidebar use &lt;code&gt;page.walk&lt;/code&gt; to traverse the blog directory and the &lt;code&gt;recents&lt;/code&gt; tag the most recent posts. These posts are then filtered with if statements to exclude non-draft content. This is all slightly hacky, since if you want to show the 5 most recent blog posts (as returned by &lt;code&gt;recents 5&lt;/code&gt;), you might have less than 5 posts after filtering out drafts. This is worked around by not dating drafts until publication (which gives them a default date in&amp;nbsp;1900).&lt;/p&gt;
&lt;p&gt;I also had to modify Hyde&amp;#8217;s &lt;code&gt;page.walk&lt;/code&gt; and &lt;code&gt;page.walk_reverse&lt;/code&gt; to walk directories in lexicographically sorted order, but I&amp;#8217;m hoping that&amp;#8217;s been fixed in git (I was using version&amp;nbsp;0.4).&lt;/p&gt;
&lt;h3&gt;S3&lt;/h3&gt;
&lt;p&gt;There is &lt;a href=&quot;http://aws.typepad.com/aws/2011/02/host-your-static-website-on-amazon-s3.html&quot;&gt;plenty&lt;/a&gt; of &lt;a href=&quot;http://docs.amazonwebservices.com/AmazonS3/latest/dev/index.html?WebsiteHosting.html&quot;&gt;documentation&lt;/a&gt; on &lt;a href=&quot;http://docs.amazonwebservices.com/AmazonS3/latest/dev/index.html?WebsiteHosting.html&quot;&gt;how&lt;/a&gt; to set up an S3 bucket as a website. It&amp;#8217;s pretty easy, I didn&amp;#8217;t have any trouble with&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;Making your existing domain name point to your S3 bucket is a little more tricky. S3 provides a &lt;span class=&quot;caps&quot;&gt;URL&lt;/span&gt; for your bucket (in my case, &lt;a href=&quot;http://www.umbrant.com.s3-website-us-west-1.amazonaws.com/&quot;&gt;http://www.umbrant.com.s3-website-us-west-1.amazonaws.com/&lt;/a&gt;). The first problem is a limitation of &lt;span class=&quot;caps&quot;&gt;DNS&lt;/span&gt;: you can&amp;#8217;t make your zone apex a &lt;span class=&quot;caps&quot;&gt;CNAME&lt;/span&gt;. If that was gibberish, it means that you can&amp;#8217;t make your plain domain name (&lt;a href=&quot;http://umbrant.com&quot;&gt;http://umbrant.com&lt;/a&gt;) an alias for another domain name, like your S3 bucket&amp;#8217;s. Subdomains don&amp;#8217;t have this limitation, which is why you&amp;#8217;re viewing this blog at &lt;a href=&quot;http://www.umbrant.com&quot;&gt;http://www.umbrant.com&lt;/a&gt;, happily &lt;span class=&quot;caps&quot;&gt;CNAME&lt;/span&gt;&amp;#8217;d to my S3 bucket. My zone apex then does a redirect to the &lt;code&gt;www&lt;/code&gt; subdomain; this redirect is a service provided by some registrars, or you can beg a friend with a&amp;nbsp;server.&lt;/p&gt;
&lt;p&gt;I just lied to you a little about how this works. Notice that if you &lt;code&gt;dig www.umbrant.com&lt;/code&gt;, you get the&amp;nbsp;following:&lt;/p&gt;
&lt;div class=&quot;code&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;dig&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;www&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;umbrant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;sr&quot;&gt;&amp;lt;snip&amp;gt;&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;QUESTION&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;SECTION&lt;/span&gt;:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;www&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;umbrant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;IN&lt;/span&gt;&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;ANSWER&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;SECTION&lt;/span&gt;:&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;www&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;umbrant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;831&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;IN&lt;/span&gt;&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;CNAME&lt;/span&gt;&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;website&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;us&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;west&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;amazonaws&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;website&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;us&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;west&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;amazonaws&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;IN&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;204.246.162.151&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;sr&quot;&gt;&amp;lt;snip&amp;gt;&lt;/span&gt;&lt;br /&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;

&lt;p&gt;My subdomain isn&amp;#8217;t actually &lt;span class=&quot;caps&quot;&gt;CNAME&lt;/span&gt;&amp;#8217;d to my S3 bucket domain name, I&amp;#8217;ve set it to alias directly to &lt;code&gt;s3-website-us-west-1.amazonaws.com&lt;/code&gt;. This is a mild optimization that saves a &lt;span class=&quot;caps&quot;&gt;DNS&lt;/span&gt; lookup; if you &lt;code&gt;dig&lt;/code&gt; my bucket domain name, you see that it&amp;#8217;s &lt;span class=&quot;caps&quot;&gt;CNAME&lt;/span&gt;&amp;#8217;d to &lt;code&gt;s3-website-us-west-1.amazonaws.com&lt;/code&gt; anyway, which finally gets turned into the &lt;span class=&quot;caps&quot;&gt;IP&lt;/span&gt; address for an S3 server (the A record). This server uses the referring domain name (&lt;code&gt;www.umbrant.com&lt;/code&gt;) to look up the S3 bucket with the same name. This system also means that if someone&amp;#8217;s already made a bucket in your region with the same name as your subdomain, you&amp;#8217;ve got to choose a different subdomain (thanks to S3&amp;#8217;s flat keyspace). In other words, when using S3, your bucket name and subdomain must be the&amp;nbsp;same.&lt;/p&gt;
&lt;p&gt;Uploading files to S3 isn&amp;#8217;t too bad. I&amp;#8217;m sure there are existing tools out there for interfacing with S3 on the commandline, but I rolled my own in Python with the &lt;a href=&quot;http://pypi.python.org/pypi/simples3/1.0&quot;&gt;SimpleS3&lt;/a&gt; library available on PyPI. It&amp;#8217;s basically rsync-for-S3 with some issues; it doesn&amp;#8217;t delete old files from S3, the parsing isn&amp;#8217;t bulletproof, and it uses modtimes to check for updates instead of checksums (which I plan on implementing soon, right now it&amp;#8217;s almost my entire blog each time I re-run Hyde). However, it does work, and it is really simple to&amp;nbsp;use.&lt;/p&gt;
&lt;div class=&quot;code&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;simples3&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;c&quot;&gt;# Config options&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;ACCESS_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;YOUR_ACCESS_KEY&amp;#39;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;SECRET_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;YOUR_SECRET_KEY&amp;#39;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;c&quot;&gt;# Change this&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;BUCKET_NAME&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;&amp;quot;www.umbrant.com&amp;quot;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;c&quot;&gt;# Change this too, make sure to edit your region and bucket name&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;BASE_URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;https://s3-us-west-1.amazonaws.com/www.umbrant.com&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;c&quot;&gt;# &lt;span class=&quot;caps&quot;&gt;NO&lt;/span&gt; &lt;span class=&quot;caps&quot;&gt;TRAILING&lt;/span&gt; &lt;span class=&quot;caps&quot;&gt;SLASH&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;SOURCE_DIR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;/home/andrew/dev/umbrant_static/deploy&amp;quot;&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;IGNORE&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;br /&gt;          &lt;span class=&quot;s&quot;&gt;&amp;quot;\.(.*).swp$&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;~$&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# ignore .swp files&lt;/span&gt;&lt;br /&gt;         &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;c&quot;&gt;# code&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;ignore_re&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;&lt;span class=&quot;caps&quot;&gt;IGNORE&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;n&quot;&gt;ignore_re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;c&quot;&gt;# open bucket&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot;&gt;bucket&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S3Bucket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BUCKET_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;access_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ACCESS_KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;br /&gt;                  &lt;span class=&quot;n&quot;&gt;secret_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SECRET_KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BASE_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;c&quot;&gt;# recursively put in all files in SOURCE_DIR&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dirs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;walk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SOURCE_DIR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;n&quot;&gt;relroot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SOURCE_DIR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;c&quot;&gt;# root directory files should not have a preceding &amp;quot;/&amp;quot;&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;c&quot;&gt;# puts the files in a blank named directory, not what we want&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relroot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relroot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;/&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;/&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;        &lt;span class=&quot;c&quot;&gt;# check in the ignore list&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;n&quot;&gt;ignore&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ignore_re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Ignoring&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;br /&gt;                &lt;span class=&quot;n&quot;&gt;ignore&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ignore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;        &lt;span class=&quot;n&quot;&gt;stat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;n&quot;&gt;metadata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;modtime&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st_mtime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;        &lt;span class=&quot;c&quot;&gt;# check if it&amp;#39;s changed with modtimes&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;n&quot;&gt;sf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;n&quot;&gt;sf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;br /&gt;        &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;n&quot;&gt;bucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;public-read&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Uploading&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;metadata&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;has_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;modtime&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; \&lt;br /&gt;        &lt;span class=&quot;n&quot;&gt;sf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;metadata&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;modtime&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st_mtime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;n&quot;&gt;bucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;public-read&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;br /&gt;                       &lt;span class=&quot;n&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Uploading&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;br /&gt;            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;br /&gt;&amp;nbsp;&lt;br /&gt;        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Skipping&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;br /&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;

&lt;h3&gt;Final&amp;nbsp;remarks&lt;/h3&gt;
&lt;p&gt;This was a pretty reasonable and fun 2 days of effort, most of which was spent on tuning the &lt;span class=&quot;caps&quot;&gt;CSS&lt;/span&gt; template and writing content, not wrangling code. Hyde doesn&amp;#8217;t feel very mature (documentation is lacking, example skeleton site is slightly broken, the sorting bug), but it works well enough and is good for people transitioning from Django. I&amp;#8217;m very positive about S3 and Amazon Web Services in general (&lt;a href=&quot;http://blog.reddit.com/2011/03/why-reddit-was-down-for-6-of-last-24.html&quot;&gt;modulo Elastic Block Store being terrible&lt;/a&gt;, but that&amp;#8217;s a rant for another day), since my site is now essentially impervious to failure. It&amp;#8217;s also pleasing to see top management like Werner Vogels dogfooding Amazon&amp;#8217;s&amp;nbsp;features.&lt;/p&gt;

   </content></entry><entry><title>Hello world!</title><author><name>Andrew Wang</name></author><link href="http://www.umbrant.com/blog/2011/hello_world.html"/><updated>2011-03-30T01:34:29Z</updated><published>2011-03-30T01:34:29Z</published><id>http://www.umbrant.com/blog/2011/hello_world.html</id><content type="html">
       

&lt;!-- Hyde::Excerpt::Begin --&gt;

&lt;p&gt;Hello world! This is my new blog and profile site, purely static &lt;span class=&quot;caps&quot;&gt;HTML&lt;/span&gt; hosted out of S3. 
Since I find this to be a neat trick, I&amp;#8217;m going to make the howto into my second-ever blog post.
This site is still very much under development, I have lots of ideas for neat features I want to add (comments being the first), but it&amp;#8217;s good enough to put&amp;nbsp;live.&lt;/p&gt;
&lt;!-- Hyde::Excerpt::End --&gt;


   </content></entry></feed>
